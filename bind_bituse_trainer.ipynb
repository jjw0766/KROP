{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdda1b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61782ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import lightning as L\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.model.modeling_bind import LitBIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f0d623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(\n",
    "    ds,\n",
    "    split_ratio,\n",
    "    seed: int,\n",
    "):\n",
    "    ds_train_test = ds.train_test_split(\n",
    "        test_size=split_ratio[2] / sum(split_ratio), seed=seed\n",
    "    )\n",
    "    ds_train_valid = ds_train_test[\"train\"].train_test_split(\n",
    "        test_size=split_ratio[1] / (split_ratio[1] + split_ratio[0]), seed=seed\n",
    "    )\n",
    "    ds_train = ds_train_valid[\"train\"]\n",
    "    ds_valid = ds_train_valid[\"test\"]\n",
    "    ds_test = ds_train_test[\"test\"]\n",
    "    return ds_train, ds_valid, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e73533b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "DATASET_NAME = 'AutoML/bitabuse'\n",
    "MINI_BATCH_SIZE=4\n",
    "N_BATCH = 4\n",
    "BASE_MODEL_NAME='google/gemma-3-1b-pt'\n",
    "EPOCHS=20\n",
    "LEARNING_RATE = 5e-5\n",
    "USE_BNTD=True\n",
    "MAX_LENGTH=32\n",
    "SPLITS = (1, 20, 79)\n",
    "INFERENCE_SENTENCE_MAX_LENGTH=256\n",
    "INFERENCE_SENTENCE_MIN_LENGTH=128\n",
    "INFERENCE_SENTENCE_N_OVERLAP=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c94499d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dac9f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.load_dataset(DATASET_NAME, split=\"train\")\n",
    "def preprocessing(example):\n",
    "    example['sentence_noisy'] = example['text'][:MAX_LENGTH]\n",
    "    example['sentence'] = example['label'][:MAX_LENGTH]\n",
    "    return example\n",
    "ds = ds.map(preprocessing)\n",
    "ds_train, ds_valid, ds_test = train_valid_test_split(\n",
    "    ds, SPLITS, SEED\n",
    ")\n",
    "ds_valid = ds_valid.select(range(len(ds_train)))\n",
    "dl_train, dl_valid, dl_test = DataLoader(ds_train, batch_size=MINI_BATCH_SIZE), DataLoader(ds_valid, batch_size=MINI_BATCH_SIZE), DataLoader(ds_test, batch_size=MINI_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3817fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use full attn gemma3\n"
     ]
    }
   ],
   "source": [
    "lit_bind = LitBIND(\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    use_bntd=USE_BNTD,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83510563",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/bind',\n",
    "    filename=f\"{DATASET_NAME.split('/')[1]}/{BASE_MODEL_NAME.split('/')[1]}\"+\"-{epoch:02d}-{valid_loss:.4f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90448224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    precision='16-mixed',\n",
    "    max_epochs=EPOCHS,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=N_BATCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name | Type | Params | Mode \n",
      "--------------------------------------\n",
      "0 | bind | BIND | 999 M  | train\n",
      "--------------------------------------\n",
      "999 M     Trainable params\n",
      "0         Non-trainable params\n",
      "999 M     Total params\n",
      "3,999.544 Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "450       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13:  47%|████▋     | 381/814 [00:53<01:00,  7.17it/s, v_num=1]"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_bind, dl_train, dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c58e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use full attn gemma3\n"
     ]
    }
   ],
   "source": [
    "lit_bind = LitBIND.load_from_checkpoint(\n",
    "    'checkpoints/bind/bitabuse/gemma-3-1b-pt-epoch=02-valid_loss=0.0189.ckpt',\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    use_bntd=USE_BNTD,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1092160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 4 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=4)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351aab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 64303/64303 [2:20:05<00:00,  7.65it/s]  \n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(lit_bind, dl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53acef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for pred in preds:\n",
    "    prediction.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9245087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df['true'] = ds_test['sentence'][:]\n",
    "df['pred'] = prediction\n",
    "df.to_csv('./results/bind_bituse_gemma3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b177378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>here's one of your pass word [re</td>\n",
       "      <td>here's one of your pass mord [re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>immediately after that, i will g</td>\n",
       "      <td>immediately after that, i will g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claims to be elon musk, just wai</td>\n",
       "      <td>claims to be alon musk, just wai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in case this does not occur - ev</td>\n",
       "      <td>in case this does not occur - ev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is insane they even know my</td>\n",
       "      <td>this is insane they even know my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257204</th>\n",
       "      <td>you have good taste, etc</td>\n",
       "      <td>you have dood taste, etc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257205</th>\n",
       "      <td>searched ip address originates f</td>\n",
       "      <td>searched ip address originates f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257206</th>\n",
       "      <td>well the previous time you visit</td>\n",
       "      <td>well the previous time you vlsit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257207</th>\n",
       "      <td>tinder iepn scam</td>\n",
       "      <td>tinder hepn scam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257208</th>\n",
       "      <td>you may very well keep on living</td>\n",
       "      <td>you may very weli keep on living</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    true                              pred\n",
       "0       here's one of your pass word [re  here's one of your pass mord [re\n",
       "1       immediately after that, i will g  immediately after that, i will g\n",
       "2       claims to be elon musk, just wai  claims to be alon musk, just wai\n",
       "3       in case this does not occur - ev  in case this does not occur - ev\n",
       "4       this is insane they even know my  this is insane they even know my\n",
       "...                                  ...                               ...\n",
       "257204          you have good taste, etc          you have dood taste, etc\n",
       "257205  searched ip address originates f  searched ip address originates f\n",
       "257206  well the previous time you visit  well the previous time you vlsit\n",
       "257207                  tinder iepn scam                  tinder hepn scam\n",
       "257208  you may very well keep on living  you may very weli keep on living\n",
       "\n",
       "[257209 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjw1214_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
