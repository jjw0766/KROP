seed: 42
cuda_visible_devices: "3"

# Dataset & Model
dataset_name: jwengr/PeOcrSanskritPreproc
base_model_name: Qwen/Qwen3-0.6B-Base
n_tokens_per_char: 8
input_chars: ""
target_chars: ""

# Training Hyperparameters
mini_batch_size: 4
n_batch: 8
epochs: 10
learning_rate: 0.0001
use_bntd: true
use_qlora: false
lora_r: 16
lora_alpha: 32
sliding_window: 12

# Sequence Lengths
train_max_length: 128
valid_max_length: 128
inference_sentence_max_length: 64
inference_sentence_min_length: 32
inference_sentence_n_overlap: 3

prefix: "n_tokens_per_char=4"