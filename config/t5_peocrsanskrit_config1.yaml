seed: 44
cuda_visible_devices: "3"

# Dataset & Model
dataset_name: jwengr/PeOcrSanskritPreproc
base_model_name: google/byt5-xl
use_qlora: true

# Training Hyperparameters
mini_batch_size: 4
n_batch: 8
epochs: 10
learning_rate: 0.0001
lora_r: 16
lora_alpha: 32

# Sequence Lengths
train_max_length: 128
valid_max_length: 128

prefix: ''