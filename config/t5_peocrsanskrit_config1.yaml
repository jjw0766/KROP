seed: 42
cuda_visible_devices: "1"

# Dataset & Model
dataset_name: jwengr/PeOcrSanskritPreproc
base_model_name: google/byt5-large
use_qlora: True

# Training Hyperparameters
mini_batch_size: 4
n_batch: 8
epochs: 10
learning_rate: 0.0001

# Sequence Lengths
train_max_length: 128
valid_max_length: 128

prefix: ''