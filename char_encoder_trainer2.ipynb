{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7107f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56512682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c08033f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightning as L\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.model.modeling_char_encoder import LitCharEncoder\n",
    "from src.data.dataset import get_train_dataloader, get_dev_dataloader, get_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe0341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "DATASET_NAME = 'jwengr/C-LLM'\n",
    "SPACE_TOKEN = '[SEP]'\n",
    "UNK_TOKEN = '[UNK]'\n",
    "PAD_TOKEN = '[PAD]'\n",
    "MINI_BATCH_SIZE=32\n",
    "N_BATCH = 1\n",
    "BASE_MODEL_NAME='google-bert/bert-base-chinese'\n",
    "EPOCHS=10\n",
    "LEARNING_RATE = 5e-5\n",
    "TRAIN_MAX_LENGTH=128\n",
    "VALID_MAX_LENGTH=128\n",
    "INFERENCE_SENTENCE_MAX_LENGTH=64\n",
    "INFERENCE_SENTENCE_MIN_LENGTH=32\n",
    "INFERENCE_SENTENCE_N_OVERLAP=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf1f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_train_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=TRAIN_MAX_LENGTH)\n",
    "dev_dl = get_dev_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=VALID_MAX_LENGTH)\n",
    "test_dl = get_test_dataloader(DATASET_NAME, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91caff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:2178: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hanzi chars as target chars.\n"
     ]
    }
   ],
   "source": [
    "lit_char_encoder = LitCharEncoder(\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP,\n",
    "    target_chars='hanzi'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f92f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/charencoder',\n",
    "    filename=f\"{DATASET_NAME.split('/')[1]}/{BASE_MODEL_NAME.split('/')[1]}\"+\"-{epoch:02d}-{valid_loss:.4f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41df54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # precision='bf16',\n",
    "    max_epochs=EPOCHS,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=N_BATCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7251e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "\n",
      "  | Name    | Type        | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | encoder | CharEncoder | 102 M  | train\n",
      "------------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.167   Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "233       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   2%|▏         | 238/10354 [00:41<29:28,  5.72it/s, v_num=23]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_char_encoder, train_dl, dev_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f604e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:2178: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using hanzi chars as target chars.\n"
     ]
    }
   ],
   "source": [
    "lit_char_encoder = LitCharEncoder.load_from_checkpoint(\n",
    "    'checkpoints/charencoder/C-LLM/bert-base-chinese-epoch=00-valid_loss=0.0559.ckpt',\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP,\n",
    "    target_chars='hanzi'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c627967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd26aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 26731/26731 [03:15<00:00, 136.87it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(lit_char_encoder, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2467f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26731/26731 [00:00<00:00, 1738774.84it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "\n",
    "for pred in tqdm(preds):\n",
    "    prediction.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "783e3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "inputs = []\n",
    "true = []\n",
    "for batch in test_dl:\n",
    "    true.extend(batch['sentence'])\n",
    "    inputs.extend(batch['sentence_noisy'])\n",
    "    categories.extend(batch['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b41978",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['input'] = inputs\n",
    "result_df['pred'] = prediction\n",
    "result_df['true'] = true\n",
    "result_df['category'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5681162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.metric import calculate_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f5fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gam {'S_D_p': 26.667, 'S_D_r': 21.622, 'S_D_f1': 23.881, 'S_C_p': 20.0, 'S_C_r': 16.216, 'S_C_f1': 17.91, 'C_D_p': 30.986, 'C_D_r': 26.829, 'C_D_f1': 28.758, 'C_C_p': 21.127, 'C_C_r': 18.293, 'C_C_f1': 19.608}\n",
      "new {'S_D_p': 52.507, 'S_D_r': 26.352, 'S_D_f1': 35.092, 'S_C_p': 40.108, 'S_C_r': 20.129, 'S_C_f1': 26.805, 'C_D_p': 55.666, 'C_D_r': 29.08, 'C_D_f1': 38.203, 'C_C_p': 41.691, 'C_C_r': 21.779, 'C_C_f1': 28.612}\n",
      "mec {'S_D_p': 65.594, 'S_D_r': 36.022, 'S_D_f1': 46.505, 'S_C_p': 57.545, 'S_C_r': 31.602, 'S_C_f1': 40.799, 'C_D_p': 71.593, 'C_D_r': 36.143, 'C_D_f1': 48.036, 'C_C_p': 61.42, 'C_C_r': 31.008, 'C_C_f1': 41.211}\n",
      "cscd {'S_D_p': 72.548, 'S_D_r': 54.277, 'S_D_f1': 62.096, 'S_C_p': 66.686, 'S_C_r': 49.891, 'S_C_f1': 57.079, 'C_D_p': 76.343, 'C_D_r': 55.657, 'C_D_f1': 64.379, 'C_C_p': 69.669, 'C_C_r': 50.791, 'C_C_f1': 58.751}\n",
      "cot {'S_D_p': 72.632, 'S_D_r': 46.939, 'S_D_f1': 57.025, 'S_C_p': 58.246, 'S_C_r': 37.642, 'S_C_f1': 45.73, 'C_D_p': 78.738, 'C_D_r': 48.765, 'C_D_f1': 60.229, 'C_C_p': 61.794, 'C_C_r': 38.272, 'C_C_f1': 47.268}\n",
      "car {'S_D_p': 55.533, 'S_D_r': 35.32, 'S_D_f1': 43.178, 'S_C_p': 45.264, 'S_C_r': 28.789, 'S_C_f1': 35.194, 'C_D_p': 63.158, 'C_D_r': 37.677, 'C_D_f1': 47.198, 'C_C_p': 51.316, 'C_C_r': 30.612, 'C_C_f1': 38.348}\n",
      "nov {'S_D_p': 38.815, 'S_D_r': 24.121, 'S_D_f1': 29.753, 'S_C_p': 30.539, 'S_C_r': 18.978, 'S_C_f1': 23.409, 'C_D_p': 43.408, 'C_D_r': 27.379, 'C_D_f1': 33.579, 'C_C_p': 33.983, 'C_C_r': 21.435, 'C_C_f1': 26.288}\n",
      "enc {'S_D_p': 58.396, 'S_D_r': 38.906, 'S_D_f1': 46.699, 'S_C_p': 46.321, 'S_C_r': 30.861, 'S_C_f1': 37.043, 'C_D_p': 58.426, 'C_D_r': 44.04, 'C_D_f1': 50.223, 'C_C_p': 47.142, 'C_C_r': 35.534, 'C_C_f1': 40.523}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for cat in set(result_df['category']):\n",
    "    cat_df = result_df[result_df['category']==cat].copy()\n",
    "    result, result_list = calculate_metric(cat_df['input'].tolist(), cat_df['true'].tolist(), cat_df['pred'].tolist())\n",
    "    print(cat, result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjw1214_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
