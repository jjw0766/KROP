{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091f8b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cec0490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightning as L\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.model.modeling_char_encoder import LitCharEncoder\n",
    "from src.data.dataset import get_train_dataloader, get_dev_dataloader, get_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6044fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=42\n",
    "DATASET_NAME = 'jwengr/ToxiBenchCN'\n",
    "SPACE_TOKEN = '[SEP]'\n",
    "UNK_TOKEN = '[UNK]'\n",
    "PAD_TOKEN = '[PAD]'\n",
    "MINI_BATCH_SIZE=32\n",
    "N_BATCH = 1\n",
    "BASE_MODEL_NAME='google-bert/bert-base-chinese'\n",
    "EPOCHS=10\n",
    "LEARNING_RATE = 5e-5\n",
    "TRAIN_MAX_LENGTH=128\n",
    "VALID_MAX_LENGTH=128\n",
    "INFERENCE_SENTENCE_MAX_LENGTH=64\n",
    "INFERENCE_SENTENCE_MIN_LENGTH=32\n",
    "INFERENCE_SENTENCE_N_OVERLAP=3\n",
    "\n",
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e64a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_train_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=TRAIN_MAX_LENGTH)\n",
    "dev_dl = get_dev_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=VALID_MAX_LENGTH)\n",
    "test_dl = get_test_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_char_encoder = LitCharEncoder(\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/charencoder',\n",
    "    filename=f\"{DATASET_NAME.split('/')[1]}/{BASE_MODEL_NAME.split('/')[1]}\"+\"-{epoch:02d}-{valid_loss:.4f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=-1,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # precision='bf16',\n",
    "    max_epochs=EPOCHS,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=N_BATCH\n",
    ")\n",
    "\n",
    "trainer.fit(lit_char_encoder, train_dl, dev_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80297843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:2178: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google-bert/bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lit_char_encoder = LitCharEncoder.load_from_checkpoint(\n",
    "    'checkpoints/charencoder/ToxiBenchCN/bert-base-chinese-epoch=00-valid_loss=1.1117.ckpt',\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a6f506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff33be11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:08<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(lit_char_encoder, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d9b999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:00<00:00, 257450.88it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "\n",
    "for pred in tqdm(preds):\n",
    "    prediction.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6a25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "inputs = []\n",
    "true = []\n",
    "for batch in test_dl:\n",
    "    true.extend(batch['sentence'])\n",
    "    inputs.extend(batch['sentence_noisy'])\n",
    "    categories.extend(batch['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf512734",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['input'] = inputs\n",
    "result_df['pred'] = prediction\n",
    "result_df['true'] = true\n",
    "result_df['category'] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c628654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>pred</th>\n",
       "      <th>true</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ğŸ’¦ğŸŒ§ï¸é»‘å­å‡ºæ¥ç­”è¯</td>\n",
       "      <td>ğŸ’¦ğŸŒ§ï¸é»‘å­å‡ºæ¥å°±è¯</td>\n",
       "      <td>åœ°åŸŸé»‘å­å‡ºæ¥ç­”è¯</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤ğŸˆµğŸ‘„ğŸ”ªğŸ‰ä»1ï¸âƒ£çš„ğŸ¶åœ¨æç¬‘</td>\n",
       "      <td>æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤ç¾¤ğŸ‘„ä¸ä¸ä»1ï¸âƒ£çš„äººåœ¨æç¬‘</td>\n",
       "      <td>æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤æ»¡å˜´é“å¾·ä»ä¹‰çš„ç‹—åœ¨æç¬‘</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯ğŸ“‰ğŸ€‚äººæ˜¯ä¸ºäº†é»‘2ï¸âƒ£ç”ŸğŸ˜…</td>\n",
       "      <td>çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯ä»¥å¥³äººæ˜¯ä¸ºäº†é»‘2ï¸âƒ£ç”Ÿæ´»</td>\n",
       "      <td>çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯æ±Ÿè¥¿äººæ˜¯ä¸ºäº†é»‘è€Œç”ŸğŸ˜…</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>é˜¿ğŸŒ¶ï¸ğŸŒŠéƒ½ä¸è¦é»‘äºº</td>\n",
       "      <td>é˜¿ğŸŒ¶ï¸ğŸŒŠéƒ½ä¸è¦é»‘äºº</td>\n",
       "      <td>é˜¿æ‹‰ä¼¯éƒ½ä¸è¦é»‘äºº</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªğŸ‘…ğŸ¶ï¼Œè¿™ç§æƒ…å†µâ¬‡è¿˜ä¸â¬‡ğŸ’€ğŸ–ï¸èµ·è¯‰æ³•é™¢</td>\n",
       "      <td>è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªåä½¬ï¼Œè¿™ç§æƒ…å†µä¸‹è¿˜ä¸ä¼šåŒğŸ–ï¸èµ·è¯‰æ³•é™¢</td>\n",
       "      <td>è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªèˆ”ç‹—ï¼Œè¿™ç§æƒ…å†µä¸‹è¿˜ä¸ä¸‹æ­»æ‰‹èµ·è¯‰æ³•é™¢</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥ğŸºåº”è¯¥â¬‡ğŸ’¦ğŸŒ§ï¸å—·</td>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥æ‹åº”è¯¥æŠµåº”ğŸŒ§ï¸å—·</td>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥ç™–åº”è¯¥ä¸‹åœ°ç‹±å—·</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥ğŸºåº”è¯¥â¬‡ğŸ’¦ğŸŒ§ï¸å—·</td>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥æ‹åº”è¯¥æŠµåº”ğŸŒ§ï¸å—·</td>\n",
       "      <td>å¼‚æ€§æ‹çš„æ‹ç«¥ç™–åº”è¯¥ä¸‹åœ°ç‹±å—·</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³2ï¸âƒ£ğŸ´ä»–å°±å¯¹äº†</td>\n",
       "      <td>æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³2ï¸âƒ£ğŸ´ä»–å°±å¯¹äº†</td>\n",
       "      <td>æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³å„¿éª‚ä»–å°±å¯¹äº†</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ä½ âœŒï¸dieä»¬åœ¨å‘¼å”¤ä½ </td>\n",
       "      <td>ä½ âœŒï¸dieæ¶åœ¨å‘¼å”¤ä½ </td>\n",
       "      <td>ä½ é‡dieä»¬åœ¨å‘¼å”¤ä½ </td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>æˆ‘7ï¸âƒ£ğŸ”Ÿæœ‰ğŸ€„ğŸ¦¶7ï¸âƒ£ğŸ”Ÿçš„äººå’Œé»‘äººğŸ¶ğŸ¶</td>\n",
       "      <td>æˆ‘7ï¸âƒ£åŒ—æœ‰ç”·æ—æ­§è§†çš„äººå’Œé»‘äººğŸ¶ğŸ¶</td>\n",
       "      <td>æˆ‘æ­§è§†æœ‰ç§æ—æ­§è§†çš„äººå’Œé»‘äººğŸ¶ğŸ¶</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ä»€ä¹ˆï¼ŸåŒè¿ğŸ˜â˜€ï¸ğŸ“•éƒ½ğŸ¢ï¼Ÿ</td>\n",
       "      <td>ä»€ä¹ˆï¼ŸåŒè¿ç”·â˜€ï¸æ—éƒ½ğŸ¢ï¼Ÿ</td>\n",
       "      <td>ä»€ä¹ˆï¼ŸåŒè¿å°æ—¥æœ¬éƒ½è·ªï¼Ÿ</td>\n",
       "      <td>emo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          input                        pred  \\\n",
       "22                    ğŸ’¦ğŸŒ§ï¸é»‘å­å‡ºæ¥ç­”è¯                   ğŸ’¦ğŸŒ§ï¸é»‘å­å‡ºæ¥å°±è¯   \n",
       "79   æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤ğŸˆµğŸ‘„ğŸ”ªğŸ‰ä»1ï¸âƒ£çš„ğŸ¶åœ¨æç¬‘  æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤ç¾¤ğŸ‘„ä¸ä¸ä»1ï¸âƒ£çš„äººåœ¨æç¬‘   \n",
       "88        çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯ğŸ“‰ğŸ€‚äººæ˜¯ä¸ºäº†é»‘2ï¸âƒ£ç”ŸğŸ˜…       çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯ä»¥å¥³äººæ˜¯ä¸ºäº†é»‘2ï¸âƒ£ç”Ÿæ´»   \n",
       "97                    é˜¿ğŸŒ¶ï¸ğŸŒŠéƒ½ä¸è¦é»‘äºº                   é˜¿ğŸŒ¶ï¸ğŸŒŠéƒ½ä¸è¦é»‘äºº   \n",
       "99     è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªğŸ‘…ğŸ¶ï¼Œè¿™ç§æƒ…å†µâ¬‡è¿˜ä¸â¬‡ğŸ’€ğŸ–ï¸èµ·è¯‰æ³•é™¢    è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªåä½¬ï¼Œè¿™ç§æƒ…å†µä¸‹è¿˜ä¸ä¼šåŒğŸ–ï¸èµ·è¯‰æ³•é™¢   \n",
       "111              å¼‚æ€§æ‹çš„æ‹ç«¥ğŸºåº”è¯¥â¬‡ğŸ’¦ğŸŒ§ï¸å—·              å¼‚æ€§æ‹çš„æ‹ç«¥æ‹åº”è¯¥æŠµåº”ğŸŒ§ï¸å—·   \n",
       "140              å¼‚æ€§æ‹çš„æ‹ç«¥ğŸºåº”è¯¥â¬‡ğŸ’¦ğŸŒ§ï¸å—·              å¼‚æ€§æ‹çš„æ‹ç«¥æ‹åº”è¯¥æŠµåº”ğŸŒ§ï¸å—·   \n",
       "162    æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³2ï¸âƒ£ğŸ´ä»–å°±å¯¹äº†    æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³2ï¸âƒ£ğŸ´ä»–å°±å¯¹äº†   \n",
       "202                 ä½ âœŒï¸dieä»¬åœ¨å‘¼å”¤ä½                  ä½ âœŒï¸dieæ¶åœ¨å‘¼å”¤ä½    \n",
       "254         æˆ‘7ï¸âƒ£ğŸ”Ÿæœ‰ğŸ€„ğŸ¦¶7ï¸âƒ£ğŸ”Ÿçš„äººå’Œé»‘äººğŸ¶ğŸ¶           æˆ‘7ï¸âƒ£åŒ—æœ‰ç”·æ—æ­§è§†çš„äººå’Œé»‘äººğŸ¶ğŸ¶   \n",
       "270                ä»€ä¹ˆï¼ŸåŒè¿ğŸ˜â˜€ï¸ğŸ“•éƒ½ğŸ¢ï¼Ÿ                ä»€ä¹ˆï¼ŸåŒè¿ç”·â˜€ï¸æ—éƒ½ğŸ¢ï¼Ÿ   \n",
       "\n",
       "                         true category  \n",
       "22                   åœ°åŸŸé»‘å­å‡ºæ¥ç­”è¯      emo  \n",
       "79   æ­£ä»€ä¹ˆæ­ªæˆä»€ä¹ˆæ ·å­äº†éƒ½æ˜¯ç¾¤æ»¡å˜´é“å¾·ä»ä¹‰çš„ç‹—åœ¨æç¬‘      emo  \n",
       "88        çˆ±å®¶ä¹¡ä¸åˆ†ç”·å¥³ï¼Œå¯æ±Ÿè¥¿äººæ˜¯ä¸ºäº†é»‘è€Œç”ŸğŸ˜…      emo  \n",
       "97                   é˜¿æ‹‰ä¼¯éƒ½ä¸è¦é»‘äºº      emo  \n",
       "99    è¿™ç”·çš„ä¹Ÿæ˜¯ä¸ªèˆ”ç‹—ï¼Œè¿™ç§æƒ…å†µä¸‹è¿˜ä¸ä¸‹æ­»æ‰‹èµ·è¯‰æ³•é™¢      emo  \n",
       "111             å¼‚æ€§æ‹çš„æ‹ç«¥ç™–åº”è¯¥ä¸‹åœ°ç‹±å—·      emo  \n",
       "140             å¼‚æ€§æ‹çš„æ‹ç«¥ç™–åº”è¯¥ä¸‹åœ°ç‹±å—·      emo  \n",
       "162    æ‰€ä»¥è¯´å˜›ä»–åœ¨å“ªä¸ªå§éƒ½æ˜¯è¿™ä¸ª13å‘³å„¿éª‚ä»–å°±å¯¹äº†      emo  \n",
       "202                ä½ é‡dieä»¬åœ¨å‘¼å”¤ä½       emo  \n",
       "254           æˆ‘æ­§è§†æœ‰ç§æ—æ­§è§†çš„äººå’Œé»‘äººğŸ¶ğŸ¶      emo  \n",
       "270               ä»€ä¹ˆï¼ŸåŒè¿å°æ—¥æœ¬éƒ½è·ªï¼Ÿ      emo  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df['pred'].apply(len)!=result_df['true'].apply(len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81dc5a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trad {'S_D_p': 62.376, 'S_D_r': 71.591, 'S_D_f1': 66.667, 'S_C_p': 51.485, 'S_C_r': 59.091, 'S_C_f1': 55.026, 'C_D_p': 75.309, 'C_D_r': 99.728, 'C_D_f1': 85.815, 'C_C_p': 68.519, 'C_C_r': 90.736, 'C_C_f1': 78.078}\n",
      "emo {'S_D_p': 53.815, 'S_D_r': 52.344, 'S_D_f1': 53.069, 'S_C_p': 8.835, 'S_C_r': 8.594, 'S_C_f1': 8.713, 'C_D_p': 87.037, 'C_D_r': 86.823, 'C_D_f1': 86.93, 'C_C_p': 24.938, 'C_C_r': 24.877, 'C_C_f1': 24.907}\n",
      "homo {'S_D_p': 19.512, 'S_D_r': 19.2, 'S_D_f1': 19.355, 'S_C_p': 5.285, 'S_C_r': 5.2, 'S_C_f1': 5.242, 'C_D_p': 87.149, 'C_D_r': 71.039, 'C_D_f1': 78.274, 'C_C_p': 31.965, 'C_C_r': 26.056, 'C_C_f1': 28.71}\n",
      "swap {'S_D_p': 5.761, 'S_D_r': 5.578, 'S_D_f1': 5.668, 'S_C_p': 2.469, 'S_C_r': 2.39, 'S_C_f1': 2.429, 'C_D_p': 69.578, 'C_D_r': 47.187, 'C_D_f1': 56.236, 'C_C_p': 31.295, 'C_C_r': 21.224, 'C_C_f1': 25.294}\n",
      "radical {'S_D_p': 40.0, 'S_D_r': 40.664, 'S_D_f1': 40.329, 'S_C_p': 11.02, 'S_C_r': 11.203, 'S_C_f1': 11.111, 'C_D_p': 84.559, 'C_D_r': 81.657, 'C_D_f1': 83.083, 'C_C_p': 35.662, 'C_C_r': 34.438, 'C_C_f1': 35.039}\n",
      "pinyin {'S_D_p': 71.548, 'S_D_r': 71.25, 'S_D_f1': 71.399, 'S_C_p': 6.276, 'S_C_r': 6.25, 'S_C_f1': 6.263, 'C_D_p': 94.14, 'C_D_r': 97.096, 'C_D_f1': 95.595, 'C_C_p': 30.594, 'C_C_r': 31.554, 'C_C_f1': 31.067}\n"
     ]
    }
   ],
   "source": [
    "for cat in set(result_df['category']):\n",
    "    cat_df = result_df[result_df['category']==cat].copy()\n",
    "    result, result_list = calculate_metric(cat_df['input'].tolist(), cat_df['true'].tolist(), cat_df['pred'].tolist())\n",
    "    print(cat, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1b794a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e6aa9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'ä½ åº”è¯¥å¯æ€œé‚£äº›ğŸ’¦ğŸŒ§ï¸7ï¸âƒ£ğŸ”Ÿçš„äºº ä»–ä»¬å°±æ˜¯æ´»åœ¨ç½‘ç»œä¸Šçš„ãŠ—ğŸ›'\n",
    "self = lit_char_encoder.encoder.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4c05708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½  1\n",
      "åº” 2\n",
      "è¯¥ 3\n",
      "å¯ 4\n",
      "æ€œ 5\n",
      "é‚£ 6\n",
      "äº› 7\n",
      "ğŸ’¦ 8\n",
      "ğŸŒ§ï¸ 9\n",
      "7ï¸âƒ£ 10\n",
      "ğŸ”Ÿ 11\n",
      "çš„ 12\n",
      "äºº 13\n",
      "[SEP] 14\n",
      "ä»– 15\n",
      "ä»¬ 16\n",
      "å°± 17\n",
      "æ˜¯ 18\n",
      "æ´» 19\n",
      "åœ¨ 20\n",
      "ç½‘ 21\n",
      "ç»œ 22\n",
      "ä¸Š 23\n",
      "çš„ 24\n",
      "ãŠ— 25\n",
      "ğŸ› 26\n"
     ]
    }
   ],
   "source": [
    "# sentence = sentence.replace(' ', self.space_token)\n",
    "encoded_ids = []\n",
    "token_type_ids = []\n",
    "for char in graphemes(sentence):\n",
    "    if char==' ':\n",
    "        char = self.space_token\n",
    "    if self.target_chars_dict:\n",
    "        if self.target_chars_dict.get(ord(char)):\n",
    "            token_type_ids.extend([1])\n",
    "        else:\n",
    "            token_type_ids.extend([0])\n",
    "    else:\n",
    "        token_type_ids.extend([1])\n",
    "    encoded_id = self.base_tokenizer.encode(char, add_special_tokens=False)[:1]\n",
    "    if not encoded_id:\n",
    "        encoded_id = [self.unk_token_id]\n",
    "    encoded_ids.extend(encoded_id)\n",
    "    print(char, len(encoded_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5b2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjw1214_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
