{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7107f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56512682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08033f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.model.modeling_char_encoder import LitCharEncoder\n",
    "from src.data.dataset import get_train_dataloader, get_dev_dataloader, get_test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe0341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42\n",
    "DATASET_NAME = 'jwengr/C-LLM'\n",
    "SPACE_TOKEN = '[SEP]'\n",
    "UNK_TOKEN = '[UNK]'\n",
    "PAD_TOKEN = '[PAD]'\n",
    "MINI_BATCH_SIZE=32\n",
    "N_BATCH = 1\n",
    "BASE_MODEL_NAME='google-bert/bert-base-multilingual-cased'\n",
    "EPOCHS=10\n",
    "LEARNING_RATE = 5e-5\n",
    "TRAIN_MAX_LENGTH=128\n",
    "VALID_MAX_LENGTH=128\n",
    "INFERENCE_SENTENCE_MAX_LENGTH=64\n",
    "INFERENCE_SENTENCE_MIN_LENGTH=32\n",
    "INFERENCE_SENTENCE_N_OVERLAP=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf1f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7d03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = get_train_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=TRAIN_MAX_LENGTH)\n",
    "dev_dl = get_dev_dataloader(DATASET_NAME, batch_size=MINI_BATCH_SIZE, max_length=VALID_MAX_LENGTH)\n",
    "test_dl = get_test_dataloader(DATASET_NAME, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91caff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:2178: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lit_char_encoder = LitCharEncoder(\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f92f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints/charencoder',\n",
    "    filename=f\"{DATASET_NAME.split('/')[1]}/{BASE_MODEL_NAME.split('/')[1]}\"+\"-{epoch:02d}-{valid_loss:.4f}\",\n",
    "    every_n_epochs=1,\n",
    "    save_top_k=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41df54b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    precision='bf16',\n",
    "    max_epochs=EPOCHS,\n",
    "    enable_checkpointing=True,\n",
    "    accumulate_grad_batches=N_BATCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name    | Type        | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | encoder | CharEncoder | 177 M  | train\n",
      "------------------------------------------------\n",
      "177 M     Trainable params\n",
      "0         Non-trainable params\n",
      "177 M     Total params\n",
      "711.898   Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "233       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 9483/10354 [18:36<01:42,  8.49it/s, v_num=53] "
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_char_encoder, train_dl, dev_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f604e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "lit_char_encoder = LitCharEncoder.load_from_checkpoint(\n",
    "    'checkpoints/charencoder/C-LLM/bert-base-multilingual-cased-epoch=00-valid_loss=0.0197.ckpt',\n",
    "    base_model_name=BASE_MODEL_NAME,\n",
    "    space_token=SPACE_TOKEN,\n",
    "    unk_token=UNK_TOKEN,\n",
    "    pad_token=PAD_TOKEN,\n",
    "    lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    inference_sentence_max_length=INFERENCE_SENTENCE_MAX_LENGTH,\n",
    "    inference_sentence_min_length=INFERENCE_SENTENCE_MIN_LENGTH,\n",
    "    inference_sentence_n_overlap=INFERENCE_SENTENCE_N_OVERLAP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c627967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "/home/jjw1214/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:  10%|‚ñà         | 2785/26731 [00:23<03:20, 119.19it/s]‚ÄãËØ¥Âà∞Ëøô,ËΩ¶Âæ∑Èí¢ËßâÂæóÊúâÂøÖË¶Å‰∏∫Â§ßÂÆ∂ËøõË°å‰∏Ä‰∏ãÁÆÄÂçïÁöÑÁßëÊôÆ,Ë∂äÈáéËΩ¶‰∏äÁöÑÊâÄË∞ì‚ÄúÂ∑ÆÈÄüÈîÅ‚ÄùÂØπ‰∫éË∂äÈáéÊÄßËÉΩÁ©∂Á´üÊúâÁùÄÊÄéÊ†∑ÁöÑÊèêÂçá„ÄÇ\n",
      "ËØ¥Âà∞ËøôÔºåËΩ¶Âæ∑Èí¢ËßâÂæóÊúâÂøÖË¶Å‰∏∫Â§ßÂÆ∂ËøõË°å‰∏Ä‰∏ãÁÆÄÂçïÁöÑÁßëÊôÆ,Ë∂äÈáéËΩ¶‰∏äÁöÑÊâÄË∞ì‚ÄãÂ∑ÆÈÄüÈîÅ‚ÄãÂØπ‰∫éË∂äÈáéÊÄßËÉΩÁ©∂Á´üÊúâÁùÄÊÄéÊ†∑ÁöÑÊèêÂçáÔºå\n",
      "Predicting DataLoader 0:  11%|‚ñà         | 2807/26731 [00:23<03:20, 119.22it/s]ÊìçÊéßÂô®ÊñπÈù¢,ÊñπÂêëÁõòÊØîËæÉËΩª,ÁÅµÊïèÂ∫¶‰πüÓ∞ØÈ´ò,ËΩ¨Âêë‰πüÈùûÂ∏∏ÁöÑÁ≤æÂáÜ,Â§©Ê∞îÂÜ∑ÁöÑËØùËøòÂèØ‰ª•ÊèêÂâçËøõË°åËøúÁ®ãÂºÄÂêØÁ©∫Ë∞É,ËΩ¶ÂÜÖÁöÑ‰∏≠ÊéßÓ≥ΩÂ±èÓ∞ØÊòØÊñπ‰æø,ÁâπÂà´ÁöÑÊô∫ËÉΩÂåñ,ËΩ¶ÂÜÖÁöÑ360ÂÖ®ÊôØÂΩ±ÂÉèÁîªÈù¢Ó∞ØÊ∏ÖÊô∞,ÂºÄËµ∑Êù•‰ø°ÂøÉÈùûÂ∏∏ÁöÑÂº∫,‰∏äÊâã‰πüÊØîËæÉÂø´„ÄÇ\n",
      "ÊìçÊéßÂô®ÊñπÈù¢ÔºåÊñπÂêëÁõòÊØîËæÉËΩª,ÁÅµÊïèÂ∫¶‰πüÈ´ò,ËΩ¨Âêë‰πüÈùûÂ∏∏ÁöÑÁ≤æÂáÜÔºåÂ§©Ê∞îÂÜ∑ÁöÑËØùËøòÂèØ‰ª•ÊèêÂâçËøõË°åËøúÁ®ãÂºÄÂêØÁ©∫Ë∞É,ËΩ¶ÂÜÖÁöÑ‰∏≠ÊéßÂ±èÊòØÊñπ‰æø,ÁâπÂà´ÁöÑÊô∫ËÉΩÂåñ,ËΩ¶ÂÜÖÁöÑ360ÂÖ®ÊôØÂΩ±ÂÉèÁîªÈù¢Ê∏ÖÊô∞,ÂºÄËµ∑Êù•‰ø°ÂøÉÈùûÂ∏∏ÁöÑÂº∫,‰∏äÊâã‰πüÊØîËæÉÂø´Ôºå\n",
      "Predicting DataLoader 0:  13%|‚ñà‚ñé        | 3346/26731 [00:27<03:15, 119.84it/s]ÂÖ≠„ÄÅÂêà‰ΩúÁîüÊïàÁöÑÊ†áÂáÜ‰πôÊñπÂ∞ÜÊ≠§È°µÈù¢ÊâìËê§Óã±Á≠æÂ≠ó„ÄÅÁõñÁ´†ÂêéÈÇÆÊîøÂØÑÁªôÁî≤Êñπ„ÄÇ\n",
      "ÂÖ≠„ÄÅÂêà‰ΩúÁîüÊïàÁöÑÊ†áÂáÜ‰πôÊñπÂ∞ÜÊ≠§È°µÈù¢ÊâìÈªëÁ≠æÂ≠ó„ÄÅÁõñÁ´†ÂêéÈÇÆÊîøÂØÑÁªôÁî≤ÊñπÔºå\n",
      "Predicting DataLoader 0:  13%|‚ñà‚ñé        | 3401/26731 [00:28<03:14, 120.02it/s]2)‰πôÊñπÊúâÊùÉËé∑ÂæóÁî≤ÊñπÂ∏ÇÁïÖÓã±ÂÆ£‰º†ÂπøÂëä‰∏äÁöÑÊîØÊåÅ„ÄÇ\n",
      "2)‰πôÊñπÊúâÊùÉËé∑ÂæóÁî≤ÊñπÂ∏ÇÂú∫ÂÆ£‰º†ÂπøÂëä‰∏äÁöÑÊîØÊåÅÔºå\n",
      "Predicting DataLoader 0:  14%|‚ñà‚ñç        | 3717/26731 [00:30<03:10, 120.93it/s]Ó†ãÓ†ãÓ†ãÓ†ãÓ†ã‚ë§ÊØèÊúàË¥¢Âä°,Áî±Áî≤Êñπ‰øùÁÆ°,‰πôÊñπÁõëÁÆ°,ÊØèÊúàÊ†∏ÁÆóÁ≠æÂ≠óÂêé,ÂàÜÁ∫¢„ÄÇ\n",
      "‚ë§ÊØèÊúàË¥¢Âä°,Áî±Áî≤Êñπ‰øùÁÆ°,‰πôÊñπÁõëÁÆ°,ÊØèÊúàÊ†∏ÁÆóÁ≠æÂ≠óÂêé,ÂàÜÁ∫¢Ôºå\n",
      "Predicting DataLoader 0:  14%|‚ñà‚ñç        | 3807/26731 [00:31<03:09, 121.09it/s]*Ó†ãÓ†ãÓ†ãÊú¨ÂêàÂêåÂê´‰∫ßÂìÅÊä•‰ª∑Ê∏ÖÂçï‰∏Ä‰ªΩ,ÁªèÂèåÊñπÁ≠æÂ≠óÁõñÁ´†Á°ÆËÆ§,‰∏éÂêàÂêåÊ≠£ÊñáÂÖ∑ÊúâÁõ∏ÂêåÁöÑÊ≥ïÂæãÊïàÂäõ;\n",
      "*Êú¨ÂêàÂêåÂê´‰∫ßÂìÅÊä•‰ª∑Ê∏ÖÂçï‰∏Ä‰ªΩ,ÁªèÂèåÊñπÁ≠æÂ≠óÁõñÁ´†Á°ÆËÆ§,‰∏éÂêàÂêåÊ≠£ÊñáÂÖ∑ÊúâÁõ∏ÂêåÁöÑÊ≥ïÂæãÊïàÂäõ;\n",
      "Predicting DataLoader 0:  14%|‚ñà‚ñç        | 3837/26731 [00:31<03:08, 121.15it/s]2.Áî≤ÊñπÂ∏åÊúõÂÆ°Ê†∏Êó∂Èó¥‰∏∫Ó†ãÓ†ãÂπ¥Ó†ãÓ†ãÊúàÓ†ãÓ†ãÊó•,ÁéØÂ¢É/ËÅå‰∏öÂÅ•Â∫∑ÂÆâÂÖ®ÁÆ°ÁêÜ‰ΩìÁ≥ªÁöÑÁ¨¨‰∏ÄÈò∂ÊÆµÂÆ°Ê†∏Êó∂Èó¥‰∏∫Ó†ãÓ†ãÓ†ãÂπ¥Ó†ãÓ†ãÊúàÓ†ãÊó•„ÄÇ\n",
      "2.Áî≤ÊñπÂ∏åÊúõÂÆ°Ê†∏Êó∂Èó¥‰∏∫Âπ¥ÊúàÊó•ÔºåÁéØÂ¢É/ËÅå‰∏öÂÅ•Â∫∑ÂÆâÂÖ®ÁÆ°ÁêÜ‰ΩìÁ≥ªÁöÑÁ¨¨‰∏ÄÈò∂ÊÆµÂÆ°Ê†∏Êó∂Èó¥‰∏∫Âπ¥ÊúàÊó•Ôºå\n",
      "Predicting DataLoader 0:  15%|‚ñà‚ñç        | 3983/26731 [00:32<03:07, 121.40it/s]Ó†ã‰∫å„ÄÅÁÆ°Êä§Ë¶ÅÊ±ÇÂèäËææÊ†áÊ†áÂáÜ1„ÄÅÓ†ã‰πôÊñπÂ∫îÂ∞ΩËÅåÂ∞ΩË¥£Â±•Ë°å„ÄäÁî®ÊùêÊûóÁÆ°Êä§ÂêàÂêå„ÄãÊâÄËßÑÂÆöÁöÑÁÆ°Êä§‰πâÂä°„ÄÇ\n",
      "‰∫å„ÄÅÁÆ°Êä§Ë¶ÅÊ±ÇÂèäËææÊ†áÊ†áÂáÜ1„ÄÅ‰πôÊñπÂ∫îÂ∞ΩËÅåÂ∞ΩË¥£Â±•Ë°å„ÄäÁî®ÊùêÊûóÁÆ°Êä§ÂêàÂêå„ÄãÊâÄËßÑÂÆöÁöÑÁÆ°Êä§‰πâÂä°Ôºå\n",
      "Predicting DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 13147/26731 [01:43<01:46, 127.36it/s]Á≠ñÁï•‰∏ÄÔºöÊÉ≥Ë¶Å‰øù‰ΩèÊú¨Èí±ÂøÖÂÖàËàçÂæóÊú¨Èí±ÔºõÁ≠ñÁï•‰∫åÔºöÁªÜÂàÜÈ£éÈô©ÊîøÁ≠ñÊøÄÊ¥ªÈü©‰ø°ËøôÈ¢óÊ£ãÔºåÁªÜÂàÜÈ£éÈô©ÊîøÁ≠ñ‰πüÂ∞±ÊòØÂàÜÂåñÈ£éÈô©ÔºõÁ≠ñÁï•‰∏âÔºöÂçïÊû™ÂåπÈ©¨Â§∫ÂõûÊñ∞Êî∂ÁõäÔºõ„ÄÄ\n",
      "Á≠ñÁï•‰∏ÄÔºöÊÉ≥Ë¶Å‰øù‰ΩèÊú¨Èí±ÂøÖÂÖàËàçÂæóÊú¨Èí±ÔºõÁ≠ñÁï•‰∫åÔºöÁªÜÂàÜÈ£éÈô©ÊîøÁ≠ñÊøÄÊ¥ªÈü©‰ø°ËøôÈ¢óÊ£ãÔºåÁªÜÂàÜÈ£éÈô©ÊîøÁ≠ñ‰πüÂ∞±ÊòØÂàÜÂåñÈ£éÈô©ÔºõÁ≠ñÁï•‰∏âÔºöÂçïÊû™ÂåπÈ©¨Â§∫ÂõûÊñ∞Êî∂ÁõäÔºõ\n",
      "Predicting DataLoader 0:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 19931/26731 [02:44<00:56, 120.84it/s]Âè™ÊòØ‰∏ÄÊÉ≥Âà∞ÈÇ£‰∫õÂç∞ËÆ∞,ÂÅöÁà∂ÊØçÁöÑÂèòÂøÉÂ¶ÇÂàÄÁªû,ÈôÜÂ¶àÂ¶àÊ≤°Â•ΩÊ∞îÁöÑÈÅì:‚ÄúÊàë‰∏çÁÆ°‰Ω†ÊòØË∞Å,‰πü‰∏çÁÆ°‰Ω†‰ª¨Âú®‰∏ÄËµ∑Â§ö‚ªìÊó∂Èó¥,ÊÄª‰πã‰Ω†Ê≤°ÊúâÁªèËøáÊàë‰ª¨Áà∂ÊØçÁöÑÂÖÅËÆ∏Â∞±ÂØπÊàëÂ•≥ÂÑøÂÅöÂá∫ËøôÁßç‰∫ãÊÉÖ,ÁÆÄÁõ¥Â∞±ÊòØ‰∏ßÂøÉ¬†\n",
      "Âè™ÊòØ‰∏ÄÊÉ≥Âà∞ÈÇ£‰∫õÂç∞ËÆ∞,ÂÅöÁà∂ÊØçÁöÑÂèòÂøÉÂ¶ÇÂàÄÁªûÔºåÈôÜÂ¶àÂ¶àÊ≤°Â•ΩÊ∞îÁöÑÈÅì:Âè™Êàë‰∏çÁÆ°‰Ω†ÊòØË∞Å,‰πü‰∏çÁÆ°‰Ω†‰ª¨Âú®‰∏ÄËµ∑Â§öÂè™Êó∂Èó¥,ÊÄª‰πã‰Ω†Ê≤°ÊúâÁªèËøáÊàë‰ª¨Áà∂ÊØçÁöÑÂÖÅËÆ∏Â∞±ÂØπÊàëÂ•≥ÂÑøÂÅöÂá∫ËøôÁßç‰∫ãÊÉÖ,ÁÆÄÁõ¥Â∞±ÊòØ‰∏ßÂøÉ\n",
      "Predicting DataLoader 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 22860/26731 [03:08<00:31, 121.58it/s]ËêßÁÅµËä∏ËØ¥ÁùÄ,ÂØπÁôΩÁãêÂÖΩÈÅì:¬†‚ÄúÂéªÂêß,‰Ω†ÁöÑ‰∏ª‰∫∫ÊúâÊ≤°ÊúâËÉΩÂäõË¶ÅÂõû‰Ω†,Â∞±Ë¶ÅÁúãÂ•πÁöÑÊú¨‰∫ã‰∫Ü„ÄÇ‚Äù\n",
      "ËêßÁÅµËä∏ËØ¥ÁùÄÔºåÂØπÁôΩÁãêÂÖΩÈÅì:ËêßÂéªÂêßÔºå‰Ω†ÁöÑ‰∏ª‰∫∫ÊúâÊ≤°ÊúâËÉΩÂäõË¶ÅÂõû‰Ω†ÔºåÂ∞±Ë¶ÅÁúãÂ•πÁöÑÊú¨‰∫ã‰∫ÜÔºåËêß\n",
      "Predicting DataLoader 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 23851/26731 [03:15<00:23, 121.89it/s]ÔªøËØ•ÊùëÊà™Ê≠¢2006Âπ¥Â∫ï,Â∑≤ÂÆûÁé∞ÈÄö]Ê∞¥„ÄÅÁîµ„ÄÅË∑Ø„ÄÅÁîµËßÜ„ÄÅÁîµËØù‰∫îÈÄö,Êó†Ë∑ØÁÅØ„ÄÇ\n",
      "ËØ•ÊùëÊà™Ëá≥2006Âπ¥Â∫ïÔºåÂ∑≤ÂÆûÁé∞ÈÄöÁâíÊ∞¥„ÄÅÁîµ„ÄÅË∑Ø„ÄÅÁîµËßÜ„ÄÅÁîµËØù‰∫îÈÄö,Êó†Ë∑ØÁÅØÔºå\n",
      "Predicting DataLoader 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 25864/26731 [03:31<00:07, 122.12it/s]183351ÓÄêÂª∫Á≠ëÁâ©ÊåâÁÖßÁáÉÁÉßÊÄßËÉΩÂèØÂàÜ‰∏∫Âì™Âá†Áßç?\n",
      "183351Âª∫Á≠ëÁâ©ÊåâÁÖßÁáÉÁÉßÊÄßËÉΩÂèØÂàÜ‰∏∫Âì™Âá†Áßç?\n",
      "Predicting DataLoader 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 26468/26731 [03:36<00:02, 122.11it/s]Ë∏•ÊãºÈü≥:qi√®¬†¬†\n",
      "Ë∏•ÊãºÈü≥:qi√®\n",
      "Ê≥®Èü≥:„Ñë„Ñß„ÑùÀãÈÉ®È¶ñ:Ë∂≥,ÈÉ®Â§ñÁ¨îÁîª:8,ÊÄªÁ¨îÁîª:15‰∫îÁ¨î86&98:KHUV‰ªìÈ¢â:RMYTVÈÉëÁ†Å:JISZÁ¨îÈ°∫ÁºñÂè∑:251212141431531ÂõõËßíÂè∑Á†Å:60144UniCode:CJK¬†\n",
      "Ê≥®Èü≥:Ê≥®Ê≥®Ê≥®Ê≥®ÈÉ®È¶ñ:Ë∂≥,ÈÉ®Â§ñÁ¨îÁîª:8,ÊÄªÁ¨îÁîª:15‰∫îÁ¨î86&98:KHUV‰ªìÈ¢â:RMYTVÈÉëÁ†Å:JISZÁ¨îÈ°∫ÁºñÂè∑:251212141431531ÂõõËßíÂè∑Á†Å:60144UniCode:CJK\n",
      "Áªü‰∏ÄÊ±âÂ≠ó¬†¬†\n",
      "Áªü‰∏ÄÊ±âÂ≠ó\n",
      "U+8E25--------------------------------------------------------------------------------‚óè¬†\n",
      "-+8E25---------------------------------------------------------------------------------\n",
      "Ë∏•qi√®¬†¬†„Ñë„Ñß„ÑùÀã‚óé¬†„Äî~ËπÄ(di√©)„ÄïÂ∞èÊ≠•Ë°åËµ∞ÁöÑÊ†∑Â≠ê,Â¶Ç‚Äú‰ºó~~ËÄåÊó•ËøõÂÖÆ,ÁæéË∂ÖËøúËÄåÈÄæËøà„ÄÇ‚Äù\n",
      "Ë∏•qi√®Ë∏•Ë∏•Ë∏•Ë∏•‚óé„Äî~Ë∏•(di√©)„ÄïÂ∞èÊ≠•Ë°åËµ∞ÁöÑÊ†∑Â≠ê,Â¶ÇË∏•‰ºó~~ËÄåÊó•ËøõÂÖÆ,ÁæéË∂ÖËøúËÄåÈÄæËøàÔºåË∏•\n",
      "Predicting DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26731/26731 [03:39<00:00, 122.06it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(lit_char_encoder, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2118311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b0bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "tokenizer.base_tokenizer.decode(\n",
      "    token_ids: Union[int, list[int], ForwardRef(\u001b[33m'np.ndarray'\u001b[39m), ForwardRef(\u001b[33m'torch.Tensor'\u001b[39m), ForwardRef(\u001b[33m'tf.Tensor'\u001b[39m)],\n",
      "    skip_special_tokens: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    clean_up_tokenization_spaces: Optional[bool] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    **kwargs,\n",
      ") -> str\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Converts a sequence of ids in a string, using the tokenizer and vocabulary with options to remove special\n",
      "tokens and clean up tokenization spaces.\n",
      "\n",
      "Similar to doing `self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))`.\n",
      "\n",
      "Args:\n",
      "    token_ids (`Union[int, list[int], np.ndarray, torch.Tensor, tf.Tensor]`):\n",
      "        List of tokenized input ids. Can be obtained using the `__call__` method.\n",
      "    skip_special_tokens (`bool`, *optional*, defaults to `False`):\n",
      "        Whether or not to remove special tokens in the decoding.\n",
      "    clean_up_tokenization_spaces (`bool`, *optional*):\n",
      "        Whether or not to clean up the tokenization spaces. If `None`, will default to\n",
      "        `self.clean_up_tokenization_spaces`.\n",
      "    kwargs (additional keyword arguments, *optional*):\n",
      "        Will be passed to the underlying model specific decode method.\n",
      "\n",
      "Returns:\n",
      "    `str`: The decoded sentence.\n",
      "\u001b[31mFile:\u001b[39m      ~/.conda/envs/jjw1214_py312/lib/python3.12/site-packages/transformers/tokenization_utils_base.py\n",
      "\u001b[31mType:\u001b[39m      method"
     ]
    }
   ],
   "source": [
    "tokenizer.base_tokenizer.decode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e2398de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Âú®ÊúÄËøëÁöÑÁ¶èÁâπËµÑÊú¨Â∏ÇÂú∫Êó•ÊäïËµÑËÄÖ‰ªãÁªç‰ºö‰∏äÔºåÈ¶ñÂ∏≠‰∫ßÂìÅÂπ≥Âè∞ÂíåËøêËê•Âπ≤']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2467f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e3c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jjw1214_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
